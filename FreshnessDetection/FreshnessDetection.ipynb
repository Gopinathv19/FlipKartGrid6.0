{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from tkinter import filedialog, messagebox\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 persons, 22.2ms\n",
      "Speed: 3.2ms preprocess, 22.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 13.5ms\n",
      "Speed: 2.3ms preprocess, 13.5ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 13.0ms\n",
      "Speed: 3.5ms preprocess, 13.0ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 22.0ms\n",
      "Speed: 3.4ms preprocess, 22.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 17.4ms\n",
      "Speed: 2.0ms preprocess, 17.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 tie, 14.1ms\n",
      "Speed: 2.5ms preprocess, 14.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 12.1ms\n",
      "Speed: 2.0ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 14.1ms\n",
      "Speed: 3.1ms preprocess, 14.1ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 16.1ms\n",
      "Speed: 2.9ms preprocess, 16.1ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 12.3ms\n",
      "Speed: 4.0ms preprocess, 12.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 25.0ms\n",
      "Speed: 3.0ms preprocess, 25.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 14.2ms\n",
      "Speed: 2.0ms preprocess, 14.2ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 15.3ms\n",
      "Speed: 1.0ms preprocess, 15.3ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 laptop, 14.9ms\n",
      "Speed: 2.0ms preprocess, 14.9ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 laptop, 23.5ms\n",
      "Speed: 4.0ms preprocess, 23.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 22.5ms\n",
      "Speed: 2.0ms preprocess, 22.5ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 25.2ms\n",
      "Speed: 3.0ms preprocess, 25.2ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 24.8ms\n",
      "Speed: 2.2ms preprocess, 24.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 24.2ms\n",
      "Speed: 2.0ms preprocess, 24.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 26.6ms\n",
      "Speed: 3.5ms preprocess, 26.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 25.7ms\n",
      "Speed: 3.0ms preprocess, 25.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 23.0ms\n",
      "Speed: 3.0ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 36.6ms\n",
      "Speed: 3.0ms preprocess, 36.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 47.7ms\n",
      "Speed: 3.4ms preprocess, 47.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 25.0ms\n",
      "Speed: 4.0ms preprocess, 25.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 25.6ms\n",
      "Speed: 3.0ms preprocess, 25.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 22.4ms\n",
      "Speed: 3.0ms preprocess, 22.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 22.1ms\n",
      "Speed: 3.2ms preprocess, 22.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 22.2ms\n",
      "Speed: 4.0ms preprocess, 22.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 23.6ms\n",
      "Speed: 2.0ms preprocess, 23.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 laptop, 22.3ms\n",
      "Speed: 3.0ms preprocess, 22.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 laptop, 23.3ms\n",
      "Speed: 5.0ms preprocess, 23.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 22.5ms\n",
      "Speed: 5.5ms preprocess, 22.5ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 21.6ms\n",
      "Speed: 4.1ms preprocess, 21.6ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 25.2ms\n",
      "Speed: 3.3ms preprocess, 25.2ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 25.7ms\n",
      "Speed: 3.0ms preprocess, 25.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 21.7ms\n",
      "Speed: 3.0ms preprocess, 21.7ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 22.0ms\n",
      "Speed: 3.1ms preprocess, 22.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 61.8ms\n",
      "Speed: 3.9ms preprocess, 61.8ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 1 cell phone, 61.5ms\n",
      "Speed: 4.0ms preprocess, 61.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 49.6ms\n",
      "Speed: 4.0ms preprocess, 49.6ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 64.7ms\n",
      "Speed: 4.0ms preprocess, 64.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cell phone, 49.8ms\n",
      "Speed: 10.0ms preprocess, 49.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cell phone, 24.7ms\n",
      "Speed: 3.0ms preprocess, 24.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cell phone, 23.0ms\n",
      "Speed: 4.4ms preprocess, 23.0ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cell phone, 22.1ms\n",
      "Speed: 3.0ms preprocess, 22.1ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 tv, 22.0ms\n",
      "Speed: 4.1ms preprocess, 22.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 tv, 24.9ms\n",
      "Speed: 3.0ms preprocess, 24.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 25.0ms\n",
      "Speed: 3.0ms preprocess, 25.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 tv, 21.2ms\n",
      "Speed: 4.0ms preprocess, 21.2ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 apple, 1 tv, 25.0ms\n",
      "Speed: 3.5ms preprocess, 25.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 apples, 1 cell phone, 25.1ms\n",
      "Speed: 3.0ms preprocess, 25.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 apples, 1 tv, 23.0ms\n",
      "Speed: 4.0ms preprocess, 23.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 apples, 1 orange, 62.5ms\n",
      "Speed: 5.0ms preprocess, 62.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 apples, 62.8ms\n",
      "Speed: 3.9ms preprocess, 62.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 apples, 1 tv, 54.7ms\n",
      "Speed: 7.5ms preprocess, 54.7ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 apples, 1 orange, 1 tv, 64.4ms\n",
      "Speed: 6.0ms preprocess, 64.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 apples, 1 orange, 1 cell phone, 60.4ms\n",
      "Speed: 4.0ms preprocess, 60.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 apples, 1 orange, 67.5ms\n",
      "Speed: 15.0ms preprocess, 67.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 apples, 1 orange, 1 tv, 66.7ms\n",
      "Speed: 6.0ms preprocess, 66.7ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 apples, 1 orange, 58.4ms\n",
      "Speed: 7.0ms preprocess, 58.4ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 apples, 1 orange, 1 tv, 70.6ms\n",
      "Speed: 5.0ms preprocess, 70.6ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 apples, 1 orange, 1 tv, 53.7ms\n",
      "Speed: 6.0ms preprocess, 53.7ms inference, 6.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 apples, 1 orange, 1 tv, 69.5ms\n",
      "Speed: 4.5ms preprocess, 69.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 apples, 1 tv, 56.0ms\n",
      "Speed: 6.0ms preprocess, 56.0ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 apples, 1 tv, 53.8ms\n",
      "Speed: 6.9ms preprocess, 53.8ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 apples, 1 tv, 62.2ms\n",
      "Speed: 7.5ms preprocess, 62.2ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 apples, 1 tv, 55.3ms\n",
      "Speed: 4.0ms preprocess, 55.3ms inference, 7.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 apples, 1 tv, 55.0ms\n",
      "Speed: 5.0ms preprocess, 55.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 apples, 1 tv, 63.3ms\n",
      "Speed: 6.0ms preprocess, 63.3ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 apples, 1 tv, 71.9ms\n",
      "Speed: 4.1ms preprocess, 71.9ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 apples, 1 tv, 64.2ms\n",
      "Speed: 6.0ms preprocess, 64.2ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 apples, 1 tv, 67.6ms\n",
      "Speed: 6.1ms preprocess, 67.6ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 apples, 1 tv, 60.9ms\n",
      "Speed: 15.5ms preprocess, 60.9ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 apples, 1 tv, 61.5ms\n",
      "Speed: 11.5ms preprocess, 61.5ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 apples, 1 tv, 58.0ms\n",
      "Speed: 6.4ms preprocess, 58.0ms inference, 7.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 apples, 1 tv, 62.1ms\n",
      "Speed: 10.4ms preprocess, 62.1ms inference, 6.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 apples, 1 tv, 67.6ms\n",
      "Speed: 7.0ms preprocess, 67.6ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 1 cell phone, 76.6ms\n",
      "Speed: 6.4ms preprocess, 76.6ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 61.8ms\n",
      "Speed: 12.1ms preprocess, 61.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 1 remote, 61.5ms\n",
      "Speed: 6.0ms preprocess, 61.5ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 64.8ms\n",
      "Speed: 6.2ms preprocess, 64.8ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 57.0ms\n",
      "Speed: 4.0ms preprocess, 57.0ms inference, 5.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 remote, 64.2ms\n",
      "Speed: 4.3ms preprocess, 64.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 tie, 53.4ms\n",
      "Speed: 6.5ms preprocess, 53.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 52.5ms\n",
      "Speed: 12.4ms preprocess, 52.5ms inference, 5.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 65.3ms\n",
      "Speed: 5.4ms preprocess, 65.3ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 60.7ms\n",
      "Speed: 6.0ms preprocess, 60.7ms inference, 7.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 70.8ms\n",
      "Speed: 6.2ms preprocess, 70.8ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 62.8ms\n",
      "Speed: 5.1ms preprocess, 62.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 tie, 62.8ms\n",
      "Speed: 6.0ms preprocess, 62.8ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 64.5ms\n",
      "Speed: 6.0ms preprocess, 64.5ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 57.3ms\n",
      "Speed: 6.0ms preprocess, 57.3ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 48.7ms\n",
      "Speed: 6.6ms preprocess, 48.7ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 56.7ms\n",
      "Speed: 6.0ms preprocess, 56.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 47.4ms\n",
      "Speed: 6.0ms preprocess, 47.4ms inference, 8.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 46.0ms\n",
      "Speed: 13.1ms preprocess, 46.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 56.3ms\n",
      "Speed: 6.0ms preprocess, 56.3ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 46.2ms\n",
      "Speed: 6.0ms preprocess, 46.2ms inference, 7.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 58.7ms\n",
      "Speed: 5.0ms preprocess, 58.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 51.5ms\n",
      "Speed: 7.1ms preprocess, 51.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " \n",
    "\n",
    "# Load YOLO model for detection\n",
    "yolo_model = YOLO('yolov8n.pt')  # Update with your local model path\n",
    "\n",
    "# Load EfficientNet for classification\n",
    "def load_efficientnet_model(checkpoint_path, num_classes=3):\n",
    "    model = models.efficientnet_b0(weights=\"IMAGENET1K_V1\")\n",
    "    num_ftrs = model.classifier[1].in_features\n",
    "    model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "efficientnet_model = load_efficientnet_model('efficientnet_apple50.pt')\n",
    "\n",
    "# Image transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# COCO class names\n",
    "COCO_CLASSES = [\n",
    "    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',\n",
    "    'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat',\n",
    "    'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',\n",
    "    'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',\n",
    "    'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'TV', 'laptop',\n",
    "    'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',\n",
    "    'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "# Classify apple freshness\n",
    "def classify_apple(image, model):\n",
    "    image = transform(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "    return predicted.item()\n",
    "\n",
    "# Save apple freshness data to CSV\n",
    "def save_to_csv(freshness_data):\n",
    "    file_exists = os.path.isfile('freshness.csv')\n",
    "    with open('freshness.csv', 'a', newline='') as csvfile:\n",
    "        fieldnames = ['Apple_ID', 'Freshness', 'Shelf_Life']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        if not file_exists:\n",
    "            writer.writeheader()  # Write header only if file doesn't exist\n",
    "        \n",
    "        for i, freshness in enumerate(freshness_data):\n",
    "            timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            shelf_life = \"2 weeks\" if freshness == 0 else \"4 days\" if freshness == 1 else \"0 days\"\n",
    "            writer.writerow({'Apple_ID': timestamp, 'Freshness': {0: 'Fresh', 1: 'Ripe', 2: 'Rotten'}[freshness], 'Shelf_Life': shelf_life})\n",
    "\n",
    "# GUI Application Class\n",
    "class AppleFreshnessApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Apple Freshness Detection\")\n",
    "        self.root.geometry(\"1200x800\")  # Slightly larger window\n",
    "        self.root.configure(bg=\"#282C34\")  # Dark theme background\n",
    "\n",
    "        # Set frame style for uniform UI\n",
    "        frame_bg = \"#383C4A\"\n",
    "        widget_fg = \"#F0F0F0\"\n",
    "\n",
    "        # Create a main frame to hold all elements\n",
    "        self.main_frame = tk.Frame(self.root, bg=frame_bg)\n",
    "        self.main_frame.pack(fill=\"both\", expand=True, padx=10, pady=10)\n",
    "\n",
    "        # Camera feed frame (vertically larger)\n",
    "        self.camera_frame = tk.Frame(self.main_frame, bg=frame_bg, width=700, height=600)\n",
    "        self.camera_frame.grid(row=0, column=0, rowspan=2, padx=10, pady=10, sticky=\"nsew\")\n",
    "\n",
    "        self.video_label = tk.Label(self.camera_frame, bg=frame_bg, fg=widget_fg, text=\"Camera Feed\", font=(\"Helvetica\", 12))\n",
    "        self.video_label.pack(fill=\"both\", expand=True)\n",
    "\n",
    "        # Frame to hold the bar chart (top right)\n",
    "        self.graph_frame = tk.Frame(self.main_frame, bg=frame_bg)\n",
    "        self.graph_frame.grid(row=0, column=1, padx=10, pady=10, sticky=\"nsew\")\n",
    "\n",
    "        # Bar chart for freshness levels\n",
    "        self.fig, self.ax = plt.subplots(figsize=(5, 2.5), facecolor=frame_bg)\n",
    "        self.ax.set_facecolor(frame_bg)\n",
    "        self.bar_chart = FigureCanvasTkAgg(self.fig, master=self.graph_frame)\n",
    "        self.bar_chart.get_tk_widget().pack(pady=10, padx=10)\n",
    "\n",
    "        # Table for shelf life information (bottom right)\n",
    "        self.table_frame = tk.Frame(self.main_frame, bg=frame_bg)\n",
    "        self.table_frame.grid(row=1, column=1, padx=10, pady=10, sticky=\"nsew\")\n",
    "\n",
    "        # Shelf life table with bold headings\n",
    "        self.shelf_life_table = ttk.Treeview(self.table_frame, columns=(\"Apple\", \"Shelf Life\"), show=\"headings\", height=5)\n",
    "        self.shelf_life_table.heading(\"Apple\", text=\"Apple\")\n",
    "        self.shelf_life_table.heading(\"Shelf Life\", text=\"Shelf Life\")\n",
    "        self.shelf_life_table.column(\"Apple\", anchor='center')\n",
    "        self.shelf_life_table.column(\"Shelf Life\", anchor='center')\n",
    "        self.shelf_life_table.pack(pady=5, padx=5)\n",
    "\n",
    "        # Customize table style (bold headings)\n",
    "        style = ttk.Style()\n",
    "        style.configure(\"Treeview.Heading\", font=(\"Helvetica\", 10, \"bold\"), background=\"#4CAF50\", foreground=\"black\")  # Change foreground to 'black'\n",
    "        style.configure(\"Treeview\", rowheight=30, font=(\"Helvetica\", 10), background=\"#f9f9f9\", foreground=\"#000000\", fieldbackground=\"#f9f9f9\")\n",
    "        # Save button for saving results\n",
    "        save_button = tk.Button(self.main_frame, text=\"Save Results\", font=(\"Helvetica\", 12), bg=\"#4CAF50\", fg=\"white\", command=self.save_results)\n",
    "        save_button.grid(row=2, column=0, padx=10, pady=10)\n",
    "\n",
    "        # Start capturing the video feed\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.update()\n",
    "\n",
    "    def plot_freshness(self, freshness_data):\n",
    "        # Clear previous plot\n",
    "        self.ax.clear()\n",
    "\n",
    "        # X and Y data for the bar chart\n",
    "        labels = [f\"Apple {i+1}\" for i in range(len(freshness_data))]\n",
    "        values = [100 if f == 0 else 60 if f == 1 else 10 for f in freshness_data]\n",
    "\n",
    "        # Assign colors based on freshness: Green for fresh, Orange for ripe, Red for rotten\n",
    "        colors = ['#4CAF50' if f == 0 else '#FF9800' if f == 1 else '#F44336' for f in freshness_data]\n",
    "\n",
    "        # Plot the bar chart\n",
    "        self.ax.bar(labels, values, color=colors)\n",
    "        self.ax.set_ylim([0, 100])\n",
    "        self.ax.set_ylabel(\"Freshness Level\", fontsize=10, color=\"#F0F0F0\")\n",
    "        self.ax.set_xlabel(\"Apple\", fontsize=10, color=\"#F0F0F0\")\n",
    "\n",
    "        # Redraw the canvas\n",
    "        self.bar_chart.draw()\n",
    "\n",
    "    def update_shelf_life_table(self, freshness_data):\n",
    "        # Clear existing table content\n",
    "        for row in self.shelf_life_table.get_children():\n",
    "            self.shelf_life_table.delete(row)\n",
    "\n",
    "        # Add shelf life information for each apple\n",
    "        for i, freshness in enumerate(freshness_data):\n",
    "            shelf_life = \"2 weeks\" if freshness == 0 else \"4 days\" if freshness == 1 else \"0 days\"\n",
    "            self.shelf_life_table.insert(\"\", \"end\", values=(f\"Apple {i+1}\", shelf_life))\n",
    "\n",
    "    def update(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.flip(frame, 1)  # Mirror the image\n",
    "            results = yolo_model(frame, conf=0.3)\n",
    "            detections = results[0].boxes\n",
    "            detected_classes = detections.cls.cpu().numpy()\n",
    "            detected_class_names = [COCO_CLASSES[int(cls)] for cls in detected_classes]\n",
    "\n",
    "            apple_detections = []  # List to store detected apples\n",
    "\n",
    "            for i in range(len(detections)):\n",
    "                xyxy = detections.xyxy[i].cpu().numpy()\n",
    "                class_name = detected_class_names[i]\n",
    "                if class_name == \"apple\":\n",
    "                    apple_detections.append(xyxy)\n",
    "\n",
    "            freshness_data = []  # To hold freshness classification results\n",
    "            if len(apple_detections) > 0:\n",
    "                for idx, xyxy in enumerate(apple_detections):\n",
    "                    x1, y1, x2, y2 = map(int, xyxy)\n",
    "                    apple_crop = frame[y1:y2, x1:x2]\n",
    "                    apple_crop_pil = Image.fromarray(cv2.cvtColor(apple_crop, cv2.COLOR_BGR2RGB))\n",
    "                    label = classify_apple(apple_crop_pil, efficientnet_model)\n",
    "                    freshness_data.append(label)\n",
    "\n",
    "                    # Draw bounding box around the apple with correct color\n",
    "                    label_text = {0: \"Fresh\", 1: \"Ripe\", 2: \"Rotten\"}[label]\n",
    "                    colors = {0: (0, 255, 0), 1: (255, 165, 0), 2: (255, 0, 0)}  # Fresh: Green, Ripe: Orange, Rotten: Red\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), colors[label], 2)\n",
    "                    cv2.putText(frame, label_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n",
    "\n",
    "                # Update the bar chart and shelf life table with freshness data\n",
    "                self.plot_freshness(freshness_data)\n",
    "                self.update_shelf_life_table(freshness_data)\n",
    "                save_to_csv(freshness_data)  # Save freshness data to CSV\n",
    "            else:\n",
    "                # If no apples are detected, clear the bar chart and table\n",
    "                self.plot_freshness([])\n",
    "                self.update_shelf_life_table([])\n",
    "\n",
    "            # Convert frame to Tkinter image\n",
    "            img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            img = Image.fromarray(img)\n",
    "            imgtk = ImageTk.PhotoImage(image=img)\n",
    "            self.video_label.imgtk = imgtk\n",
    "            self.video_label.configure(image=imgtk)\n",
    "\n",
    "        # Recursively call update to keep fetching frames\n",
    "        self.root.after(10, self.update)\n",
    "\n",
    "    def save_results(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if ret:\n",
    "            file_name = filedialog.asksaveasfilename(defaultextension=\".jpg\", filetypes=[(\"JPEG\", \"*.jpg\"), (\"PNG\", \"*.png\")])\n",
    "            if file_name:\n",
    "                cv2.imwrite(file_name, frame)\n",
    "                messagebox.showinfo(\"Success\", \"Image saved successfully!\")\n",
    "\n",
    "    def on_closing(self):\n",
    "        self.cap.release()\n",
    "        self.root.destroy()\n",
    "\n",
    "# Initialize Tkinter window\n",
    "root = tk.Tk()\n",
    "app = AppleFreshnessApp(root)\n",
    "root.protocol(\"WM_DELETE_WINDOW\", app.on_closing)\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envpytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
